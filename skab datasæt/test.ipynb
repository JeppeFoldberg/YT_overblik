{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "# from datetime import datetime\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(path): \n",
    "    with open(path) as f:\n",
    "        # read file\n",
    "        content = f.read()\n",
    "        # parse with bs\n",
    "        soup = bs(content, 'lxml')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history = parse_html('../Rådata/Takeout/YouTube and YouTube Music/history/watch-history.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_video(tag): \n",
    "    '''\n",
    "    Filter to remove ads and videos that still ex\n",
    "    takes a block of html code and returns a boolean with whether this is an ad or not\n",
    "    '''\n",
    "    not_an_ad = not(bool(re.search('From Google Ads', tag.get_text())))\n",
    "    not_deleted = len(tag.find_all('a')) > 2\n",
    "    return (not_an_ad & not_deleted)\n",
    "       \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30345 entries; 28332 after cleaning. 2013 ads and deleted videos removed!\n"
     ]
    }
   ],
   "source": [
    "def parse_watch_history(soup):\n",
    "    '''takes a parsed tree of watch history (wh) from beautiful soup and returns a simple df with the relevant data'''\n",
    "    # hver yderste blok har klassen 'outer-cell mdl-cell mdl-cell--12-col mdl-shadow--2dp' - Her henter vi dem alle sammen\n",
    "    blocks = soup.find_all(class_ = 'outer-cell mdl-cell mdl-cell--12-col mdl-shadow--2dp')\n",
    "    blocks_cleaned = [block for block in blocks if is_a_video(block)]\n",
    "    print(f'{len(blocks)} entries; {len(blocks_cleaned)} after cleaning. {len(blocks) - len(blocks_cleaned)} ads and deleted videos removed!')\n",
    "    return blocks_cleaned\n",
    "\n",
    "watch_history_blocks = parse_watch_history(watch_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a video and an add for testing! \n",
    "video = watch_history_blocks[0]\n",
    "ad =  watch_history_blocks[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To create the dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det store problem her er at få datoen til at blive hentet rigtigt fra teksten solvom der kan være overlap med titlen af kanalen (hvis den slutter på et tal) eller hvis den har en mærkelig sætning der siger hvornår den er set på - det kan forekomme i nogle tilfælde. \n",
    "\n",
    "Den foreløbige løsning er kombinationen af f og r strenge - her kan variable puttes ind i en regex. Det er vigtigt at huske på at kvantifiers i regex '{}' så skal have et dobbelt sæt klammer rund om sig!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of this is to find out how to do the cleansing properly - it should work now but it is here for posterity in case it needs fixing! \n",
    "watched_at_videos = [video for video in watch_history_blocks if re.search(r'Watched at \\d\\d:\\d\\d', video.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Watched at 22:16'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watched_at_video = watched_at_videos[0]\n",
    "watched_at_video.text\n",
    "match = re.search(r'Watched at \\d\\d:\\d\\d', watched_at_video.text)\n",
    "match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTubeWatched YouTube Music Ableton Walkthroughs: Part 1Red Means RecordingWatched at 22:169 Nov 2019, 23:05:11 CESTProducts: YouTubeWhy is this here? This activity was saved to your Google Account because the following settings were on: YouTube watch history. You can control these settings  here.\n",
      "Red\\ Means\\ RecordingWatched at 22:16(\\d?\\d \\w{3,4} \\d{4}, \\d{2}:\\d{2}:\\d{2}[^P]*)\n",
      "Red\\ Means\\ RecordingWatched at 22:16(\\d?\\d \\w{3,4} \\d{4}, \\d{2}:\\d{2}:\\d{2}[^P]*) <re.Match object; span=(57, 117), match='Red Means RecordingWatched at 22:169 Nov 2019, 23>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9 Nov 2019, 23:05:11 CEST'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of this is to find out how to do the cleansing properly - it should work now but it is here for posterity in case it needs fixing! \n",
    "\n",
    "# match = re.search(watch_history_blocks[0].text, r'\\\\n\\d?\\d \\w{3,4} \\d{4}, \\d{2}:\\d{2}:\\d{2}[^P]*')\n",
    "# print(match)\n",
    "# watch_history_blocks[0].find(class_ = 'content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1').text\n",
    "block = watched_at_video\n",
    "print(block.text)\n",
    "links = block.find_all('a')\n",
    "\n",
    "channel_title = re.escape(links[1].text)\n",
    "watched_at = re.search(r'Watched at \\d\\d:\\d\\d', block.text) # Watched at 22:16\n",
    "\n",
    "if watched_at:\n",
    "   search_string = fr'{channel_title}{watched_at.group()}(\\d?\\d \\w{{3,4}} \\d{{4}}, \\d{{2}}:\\d{{2}}:\\d{{2}}[^P]*)'  \n",
    "else:\n",
    "    search_string = fr'{channel_title}(\\d?\\d \\w{{3,4}} \\d{{4}}, \\d{{2}}:\\d{{2}}:\\d{{2}}[^P]*)' \n",
    "\n",
    "print(search_string)\n",
    "\n",
    "match = re.search(search_string, block.text)\n",
    "\n",
    "print(search_string, match)\n",
    "match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_titles = []\n",
    "video_links = []\n",
    "channel_titles = []\n",
    "channel_links = []\n",
    "date_watched = []\n",
    "\n",
    "# i = 0 # debugging! \n",
    "for block in watch_history_blocks:\n",
    "    links = block.find_all('a')\n",
    "    \n",
    "    video_titles.append(links[0].text)\n",
    "    video_links.append(links[0]['href'])\n",
    "    channel_title = links[1].text # get channel title for date search! \n",
    "    channel_titles.append(channel_title)\n",
    "    channel_links.append(links[1]['href'])\n",
    "\n",
    "    # Useful for debugging\n",
    "    # i += 1\n",
    "    # print(f'{len(links)} links; entry {i} with title {links[0].text}')\n",
    "\n",
    "    # find out if text has the weird watched at text so we can avoid it! \n",
    "    watched_at = re.search(r'Watched at \\d\\d:\\d\\d', block.text) \n",
    "    channel_title = re.escape(channel_title) # escape so we avoid problems with channel titles full of weird characters! \n",
    "\n",
    "    if watched_at:\n",
    "        search_string = fr'{channel_title}{watched_at.group()}(\\d?\\d \\w{{3,4}} \\d{{4}}, \\d{{2}}:\\d{{2}}:\\d{{2}}[^P]*)'  \n",
    "    else:\n",
    "        search_string = fr'{channel_title}(\\d?\\d \\w{{3,4}} \\d{{4}}, \\d{{2}}:\\d{{2}}:\\d{{2}}[^P]*)' \n",
    "\n",
    "    date_string = re.search(search_string, block.text)\n",
    "\n",
    "    if watched_at:\n",
    "        date_watched.append(parse(date_string.group(1)))\n",
    "    else:\n",
    "        date_watched.append(parse(date_string.group(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure that we only get the ids! \n",
    "for video in video_links:\n",
    "    match = re.search(r'https://www.youtube.com/watch\\?v=(.*)', video)\n",
    "    if not match:\n",
    "        print(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(date_watched[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_string = re.search(r'\\d?\\d \\w{3} \\d{4}, \\d{2}:\\d{2}:\\d{2}[^P]*', video.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 Aug 2022, 13:27:58 CEST'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = parse(date_string[0])\n",
    "date_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-09T13:27:58+02:00\n",
      "2022-08-09 13:27:58+02:00\n"
     ]
    }
   ],
   "source": [
    "print(date.isoformat())\n",
    "print(pd.Timestamp(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.DataFrame({\n",
    "#     'video_title' : video_titles,\n",
    "#     'video_link' : video_links,\n",
    "#     'channel_title' : channel_titles,\n",
    "#     'channel_link' : channel_links,\n",
    "#     'date_watched' : date_watched\n",
    "# })\n",
    "dataframe = pd.read_csv('../Renset data/watch_history_df.csv', index_col=0, parse_dates=['date_watched'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.rename(columns={'video_link' : 'video_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-08-09T13:27:58+02:00'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.loc[0, 'date_watched'].isoformat()\n",
    "# dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting more data from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new imports! \n",
    "import googleapiclient.discovery\n",
    "import google_auth_oauthlib.flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points used for getting all captions: 5.7E+06, \n",
      "points in a day: 1.0E+04\n"
     ]
    }
   ],
   "source": [
    "# points used for downloading all my data\n",
    "#  \n",
    "# points_pr_day = 10000\n",
    "# n_videos = 28332\n",
    "# caption_points = 200 * n_videos\n",
    "# video_info = 0 * n_videos\n",
    "\n",
    "# points = caption_points + video_info\n",
    "# print(f'points used for getting all captions: {points:.1E}, \\n\\\n",
    "# points in a day: {points_pr_day:.1E}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials.json') as f:\n",
    "    credentials = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataframe.head(1)\n",
    "ids = test_data.video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=859790329153-3ncuv1l9tuhpb0nocncthbhbiv62r7jm.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=aXgvXp0qgej2ch9AMeWy93feR0bD7i&prompt=consent&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "def get_caption(video_id):\n",
    "    '''\n",
    "    Takes a video ID and retrieves the caption from YouTubes API\n",
    "    '''\n",
    "    pass\n",
    "    \n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "ids = test_data['video_id']\n",
    "client_secrets_file = '../credentials.json' \n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "\n",
    "# API client\n",
    "flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file, scopes)\n",
    "\n",
    "credentials = flow.run_console()\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    oPpzT6JKGk0\n",
       "Name: video_id, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'youtube#captionListResponse', 'etag': 'POYMJm1npY1EZRySg8qwTUvFyso', 'items': [{'kind': 'youtube#caption', 'etag': 'NB05FRBEu0z6askKT8n_8zmnMR0', 'id': 'AUieDaYGRdTIARzPgskcXiH3ZmPcjGvUZrXIFRA7az4Z4QfyJ3Q', 'snippet': {'videoId': 'oPpzT6JKGk0', 'lastUpdated': '2022-07-30T07:16:09.575042Z', 'trackKind': 'asr', 'language': 'en', 'name': '', 'audioTrackType': 'unknown', 'isCC': False, 'isLarge': False, 'isEasyReader': False, 'isDraft': False, 'isAutoSynced': False, 'status': 'serving'}}, {'kind': 'youtube#caption', 'etag': 'tpqgwaRR0pf0vTcw91dQt9DXEII', 'id': 'AUieDaZKDswN2qMsRgAHATSSIF6rT84FwWmad2grobN-', 'snippet': {'videoId': 'oPpzT6JKGk0', 'lastUpdated': '2022-07-29T14:41:49.876101Z', 'trackKind': 'standard', 'language': 'en', 'name': '', 'audioTrackType': 'unknown', 'isCC': False, 'isLarge': False, 'isEasyReader': False, 'isDraft': False, 'isAutoSynced': False, 'status': 'serving'}}]}\n"
     ]
    }
   ],
   "source": [
    "request = youtube.captions().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=ids[0]\n",
    "    )\n",
    "\n",
    "response = request.execute()\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/captions/watch%3Fv%3DoPpzT6JKGk0? returned \"The caption track could not be found. Check the value of the request's <code>id</code> parameter to ensure that it is correct.\". Details: \"[{'message': \"The caption track could not be found. Check the value of the request's <code>id</code> parameter to ensure that it is correct.\", 'domain': 'youtube.caption', 'reason': 'captionNotFound', 'location': 'id', 'locationType': 'parameter'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jeppefoldberg/Documents/YT_overblik/skab datasæt/test.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeppefoldberg/Documents/YT_overblik/skab%20datas%C3%A6t/test.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m request \u001b[39m=\u001b[39m youtube\u001b[39m.\u001b[39mcaptions()\u001b[39m.\u001b[39mdownload(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeppefoldberg/Documents/YT_overblik/skab%20datas%C3%A6t/test.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwatch?v=oPpzT6JKGk0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeppefoldberg/Documents/YT_overblik/skab%20datas%C3%A6t/test.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jeppefoldberg/Documents/YT_overblik/skab%20datas%C3%A6t/test.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m response \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39;49mexecute()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeppefoldberg/Documents/YT_overblik/skab%20datas%C3%A6t/test.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniforge3/envs/yt_overblik/lib/python3.10/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m positional_parameters_enforcement \u001b[39m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/yt_overblik/lib/python3.10/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m     callback(resp)\n\u001b[1;32m    937\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[39mraise\u001b[39;00m HttpError(resp, content, uri\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/captions/watch%3Fv%3DoPpzT6JKGk0? returned \"The caption track could not be found. Check the value of the request's <code>id</code> parameter to ensure that it is correct.\". Details: \"[{'message': \"The caption track could not be found. Check the value of the request's <code>id</code> parameter to ensure that it is correct.\", 'domain': 'youtube.caption', 'reason': 'captionNotFound', 'location': 'id', 'locationType': 'parameter'}]\">"
     ]
    }
   ],
   "source": [
    "request = youtube.captions().download(\n",
    "    id = 'oPpzT6JKGk0'\n",
    ")\n",
    "\n",
    "response = request.execute()\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch?v=oPpzT6JKGk0'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79533c0d0a233a1445e6036526d0f86e3fa1cf746f28d46beb4a448a63b5bfb4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('yt_overblik')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
